import json
import os
from pathlib import Path
import google.generativeai as genai
from pydub import AudioSegment
import tempfile
from typing import List, Dict
import time

# è¨­å®šä½ çš„ Gemini API key
GEMINI_API_KEY = ""
genai.configure(api_key=GEMINI_API_KEY)

# PROMPT_TEXT = """
# You are a Music Supervisor analyzing a background music segment from a vlog.
# You are listening to a **BGM segment** that plays during a specific part of the video.

# Analyze this audio clip and output a JSON object with exactly these fields:

# 1. "mood_tags": A list of exactly 2 adjectives from this allowed list: 
#    ["Happy", "Sad", "Epic", "Chill", "Tense", "Romantic", "Upbeat", "Dark", "Funny", "Sentimental"]
# 2. "energy": ("Low", "Medium", "High")
# 3. "instrumentation": Key instruments heard (e.g., "Acoustic Guitar, Piano", "Synth, Bass, Drums")
# 4. "has_vocals": (true/false) -> Is there ANY human voice (singing/rapping/humming)?
# 5. "loop_suitability": (1-10) -> How repetitive/steady? (10 = Perfect steady loop, 1 = Too many changes/stops)
# 6. "suggested_genre": The specific sub-genre (e.g., "Lo-fi Hip Hop", "Epic Orchestral", "Tech House")
# 7. "video_pairing": A one-sentence description of the *perfect* video scene for this track (e.g., "Fast-paced travel montage" or "Sad emotional dialogue")

# Output ONLY the JSON object. No markdown formatting, no code blocks, just the raw JSON.
# """

PROMPT_TEXT = """
You are a Music Supervisor creating BGM descriptions for a video segment.
You are analyzing a **background music segment** that should match a specific scene.

Given the scene information:
- Visual description: {visual_caption}
- Scene category: {scene_category}
- Duration: {duration} seconds
- Current energy level: {energy}
- Mood tags: {mood_tags}

Output a JSON object with exactly these fields:

1. "start_time": (The segment start time in seconds)
2. "end_time": (The segment end time in seconds)
3. "scene_type": (The scene category: Dialogue, Montage, Transit, Static, or Action)
4. "mood_tags": Keep the original mood tags: {mood_tags}
5. "energy": Keep the original energy level: {energy}
6. "music_description": A concise description of the ideal BGM (e.g., "Light acoustic guitar with soft percussion", "Upbeat electronic beat with synth melody")
7. "instrumentation": Suggested key instruments (e.g., "Acoustic Guitar, Light Percussion", "Synth, Bass, Drums")
8. "has_vocals": (true/false) -> Should this segment have vocals? (Generally false for most BGM, true for intro/outro or special moments)
9. "tempo": (Slow, Medium, Fast) -> Suggested tempo based on scene pacing
10. "transition_type": ("Fade", "Cut", "Crossfade", "Continue") -> How should this transition from previous segment?
11. "suggested_genre": The specific genre from: {suggested_genre}
12. "prominence": ("Background", "Foreground", "Ambient") -> How prominent should music be?
    - "Background": Dialogue scenes, music stays subtle
    - "Foreground": Montages, action, music drives the scene
    - "Ambient": Scenic shots, music creates atmosphere
13. "reference_style": A brief style reference (e.g., "Similar to travel vlog BGM", "Like lo-fi study music", "Cinematic documentary style")

Output ONLY the JSON object.
"""

def time_to_seconds(time_str: str) -> float:
    """å°‡æ™‚é–“å­—ä¸² (MM:SS) è½‰æ›ç‚ºç§’æ•¸"""
    parts = time_str.split(':')
    if len(parts) == 2:
        minutes, seconds = parts
        return int(minutes) * 60 + float(seconds)
    elif len(parts) == 3:
        hours, minutes, seconds = parts
        return int(hours) * 3600 + int(minutes) * 60 + float(seconds)
    else:
        return float(time_str)

def extract_audio_segment(audio_path: str, start_time: float, end_time: float, output_path: str):
    """å¾éŸ³è¨Šæª”æ¡ˆä¸­æå–æŒ‡å®šæ™‚é–“æ®µ"""
    audio = AudioSegment.from_file(audio_path)
    
    # è½‰æ›ç‚ºæ¯«ç§’
    start_ms = int(start_time * 1000)
    end_ms = int(end_time * 1000)
    
    # æå–ç‰‡æ®µ
    segment = audio[start_ms:end_ms]
    
    # åŒ¯å‡º
    segment.export(output_path, format="mp3")
    print(f"  âœ“ Extracted segment: {start_time}s - {end_time}s")

def caption_audio_with_gemini(audio_path: str, model_name: str = "gemini-2.0-flash-exp") -> Dict:
    """ä½¿ç”¨ Gemini ç‚ºéŸ³è¨Šç‰‡æ®µç”Ÿæˆ caption"""
    try:
        # ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ
        print(f"  âŸ³ Uploading audio to Gemini...")
        audio_file = genai.upload_file(audio_path)
        
        # ç­‰å¾…æª”æ¡ˆè™•ç†å®Œæˆ
        while audio_file.state.name == "PROCESSING":
            time.sleep(1)
            audio_file = genai.get_file(audio_file.name)
        
        if audio_file.state.name == "FAILED":
            raise ValueError("Audio file processing failed")
        
        print(f"  âœ“ Audio uploaded successfully")
        
        # å»ºç«‹æ¨¡å‹ä¸¦ç”Ÿæˆ caption
        model = genai.GenerativeModel(model_name)
        response = model.generate_content([audio_file, PROMPT_TEXT])
        
        # è§£æ JSON å›æ‡‰
        response_text = response.text.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown æ ¼å¼
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        if response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        
        caption_data = json.loads(response_text.strip())
        
        # æ¸…ç†ä¸Šå‚³çš„æª”æ¡ˆ
        genai.delete_file(audio_file.name)
        
        return caption_data
        
    except Exception as e:
        print(f"  âœ— Error captioning audio: {e}")
        return None

def process_vlog_bgm(video_caption_json_path: str, bgm_audio_path: str, output_json_path: str):
    """
    è™•ç†æ•´å€‹ vlog BGMï¼Œç‚ºæ¯å€‹ç‰‡æ®µç”Ÿæˆ audio caption
    
    Args:
        video_caption_json_path: åŒ…å«å ´æ™¯è³‡è¨Šçš„ JSON æª”æ¡ˆè·¯å¾‘
        bgm_audio_path: èƒŒæ™¯éŸ³æ¨‚éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ (å·²åš source separation)
        output_json_path: è¼¸å‡ºçš„ audio caption JSON æª”æ¡ˆè·¯å¾‘
    """
    # è®€å–å ´æ™¯è³‡è¨Š
    print(f"ğŸ“– Loading video captions from: {video_caption_json_path}")
    with open(video_caption_json_path, 'r', encoding='utf-8') as f:
        scenes = json.load(f)
    
    print(f"ğŸ“Š Found {len(scenes)} scenes to process")
    print(f"ğŸµ BGM audio file: {bgm_audio_path}")
    print()
    
    # å»ºç«‹è‡¨æ™‚ç›®éŒ„å­˜æ”¾éŸ³è¨Šç‰‡æ®µ
    temp_dir = tempfile.mkdtemp()
    print(f"ğŸ“ Temporary directory: {temp_dir}")
    print()
    
    results = []
    
    for idx, scene in enumerate(scenes, 1):
        print(f"[{idx}/{len(scenes)}] Processing scene: {scene['start']} - {scene['end']}")
        print(f"  Scene: {scene['visual_caption'][:60]}...")
        
        # è½‰æ›æ™‚é–“
        start_sec = time_to_seconds(scene['start'])
        end_sec = time_to_seconds(scene['end'])
        
        # æå–éŸ³è¨Šç‰‡æ®µ
        segment_path = os.path.join(temp_dir, f"segment_{idx:03d}.mp3")
        extract_audio_segment(bgm_audio_path, start_sec, end_sec, segment_path)
        
        # ä½¿ç”¨ Gemini ç”Ÿæˆ caption
        print(f"  ğŸ¤– Generating audio caption with Gemini...")
        caption = caption_audio_with_gemini(segment_path)
        
        if caption:
            # åˆä½µåŸå§‹å ´æ™¯è³‡è¨Šå’ŒéŸ³è¨Š caption
            result = {
                "start": scene['start'],
                "end": scene['end'],
                "visual_caption": scene['visual_caption'],
                "scene_category": scene['scene_category'],
                "audio_caption": caption
            }
            results.append(result)
            print(f"  âœ“ Caption generated successfully")
            print(f"    Mood: {caption.get('mood_tags', [])}")
            print(f"    Genre: {caption.get('suggested_genre', 'N/A')}")
        else:
            print(f"  âœ— Failed to generate caption")
        
        print()
        
        # åˆªé™¤è‡¨æ™‚éŸ³è¨Šç‰‡æ®µ
        if os.path.exists(segment_path):
            os.remove(segment_path)
        
        # é¿å… API rate limit
        time.sleep(1)
    
    # æ¸…ç†è‡¨æ™‚ç›®éŒ„
    os.rmdir(temp_dir)
    
    # å„²å­˜çµæœ
    print(f"ğŸ’¾ Saving results to: {output_json_path}")
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Processing complete! Generated {len(results)} audio captions")

if __name__ == "__main__":
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    VIDEO_CAPTION_JSON = "Vlog Captions 2.json"  # ä½ çš„å ´æ™¯ JSON æª”æ¡ˆ
    BGM_AUDIO_FILE = "../test_audio.mp3"         # åˆ†é›¢å‡ºä¾†çš„èƒŒæ™¯éŸ³æ¨‚
    OUTPUT_JSON = "audio_captions_2.json"          # è¼¸å‡ºçš„ audio caption
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(VIDEO_CAPTION_JSON):
        print(f"âŒ Error: Video caption JSON not found: {VIDEO_CAPTION_JSON}")
        exit(1)
    
    if not os.path.exists(BGM_AUDIO_FILE):
        print(f"âŒ Error: BGM audio file not found: {BGM_AUDIO_FILE}")
        exit(1)
    
    # è™•ç†
    process_vlog_bgm(VIDEO_CAPTION_JSON, BGM_AUDIO_FILE, OUTPUT_JSON)